<div style="text-align: center;">
  <h1>Hallucination Elimination and Semantic Enhancement Framework for Vision-Language Models in Traffic Scenarios</h1>
</div>

![Logo](images/label_coda+nuscenes_13.jpg)

## :fire: News
&#8226; This paper is submitted to IEEE Transactions on Intelligent Transportation Systems.

&#8226; [Watch the demo video](https://github.com/fjq-tongji/HCOENet/releases/download/demo/Video.Demo.mp4)

&#8226; CODA_desc.rar and nuScenes_desc.rar are the created datasets.


## :book: Model
![Logo](images/overall39.jpg)

## :star: Results
### Quantitative results  
Table 1. Evaluation results of five LVLMs on the POPE benchmark under three negative sampling settings. (\%)  
![Logo](images/Tab1.jpg)  
Table 2. Comparison results between different mPLUG-Owl models on the POPE benchmark. (\%)  
![Logo](images/Tab2.jpg)  
Table 3. Comparison with the GPT-4o model on the POPE benchmark. B denotes billion and T denotes trillion. (\%)  
![Logo](images/Tab3.jpg)
### Qualitative results  
![Logo](images/campus_img.jpg)  

## :scroll: Citation
@article{Hallucination,  
  title={Hallucination Elimination and Semantic Enhancement Framework for Vision-Language Models in Traffic Scenarios},  
  author={Jiaqi Fan and Jianhua Wu and Hongqing Chu and Quanbo Ge and Bingzhao Gao},  
  year={2024},  
  url={https://api.semanticscholar.org/CorpusID:274610465}  
}  

